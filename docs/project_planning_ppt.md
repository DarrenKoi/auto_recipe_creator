# CD-SEM Recipe 셋업 자동화 프로젝트 — 기획 보고서 (PPT 슬라이드)

> 이 문서는 PPT 슬라이드 형식으로 변환하기 위한 콘텐츠 원본입니다.
> 각 슬라이드는 `---`로 구분되며, 상단 요약 문장 + 본문(1~2컬럼) 구조입니다.

---

## Slide 1. 표지

### CD-SEM / VeritySEM Recipe 셋업 자동화

**AI 기반 VLM + RAG 시스템으로 반도체 계측 장비 Recipe 작업을 자동화**

| 항목 | 내용 |
|------|------|
| 소속 | AI/DT TF Solution Team |
| 작성일 | 2025.01 |
| 문서 버전 | v1.0 |
| 대상 장비 | CD-SEM, VeritySEM |

---

## Slide 2. Executive Summary

**VLM과 CCTV 기반 RAG를 결합하여, 엔지니어의 반복 작업을 50% 이상 줄이고 자동화 성공률 90%를 달성하는 시스템 구축**

- **문제**: Recipe 셋업은 엔지니어가 RCS에서 수동으로 반복 조작 → 시행착오 빈번, 인력 의존도 높음
- **해법**: VLM(화면 인식) + RAG(전문가 지식 검색) + GUI 자동화(마우스/키보드) 결합
- **핵심 차별점**: Fine-tuning 없이 CCTV 영상에서 추출한 전문가 노하우를 RAG로 활용
- **목표 성과**: 자동화 성공률 90%↑, 작업 시간 50%↓, 사람 개입 20%↓

---

## Slide 3. 배경 및 현황 (Why)

**현재 Recipe 셋업은 100% 수동 작업으로, 숙련 엔지니어의 시간과 노하우에 전적으로 의존**

| As-Is (현재 문제점) | 영향 |
|---------------------|------|
| 엔지니어가 RCS GUI에서 마우스/키보드로 수동 조작 | 1건당 상당한 시간 소요, 반복 피로 누적 |
| 측정 위치를 시행착오로 조정 (위치 잡기 → 측정 → 실패 → 재조정) | 비효율적 반복 작업, 품질 편차 발생 |
| 노하우가 숙련 엔지니어 개인에 의존 | 인력 이탈 시 지식 유실 위험 |
| 동일 작업을 장비마다 반복 수행 | 장비 수 증가에 비례하여 인력 부담 증가 |
| 작업 이력이 체계적으로 관리되지 않음 | 문제 재발 시 원인 추적 어려움 |

---

## Slide 4. 프로젝트 목표 및 방향 (What)

**AI가 화면을 보고, 전문가처럼 판단하고, 직접 조작하는 "Supervised Autonomy" 시스템 구축**

| As-Is (수동 프로세스) | To-Be (AI 자동화 프로세스) |
|----------------------|--------------------------|
| 엔지니어가 직접 화면 확인 | VLM이 화면 상태를 자동 인식 (>90% 정확도) |
| 경험에 의존한 판단 | CCTV 전문가 데이터 기반 RAG 추론 |
| 수동 마우스/키보드 조작 | AI Agent가 자동 입력 실행 (<200ms) |
| 실패 시 수동 재조정 | 자동 위치/파라미터 적응형 조정 |
| 개인 노하우에 의존 | MongoDB에 작업 이력 축적, 지식 자산화 |
| 단일 장비에 1명 엔지니어 배정 | 1명이 다수 장비 모니터링 가능 |

---

## Slide 5. 핵심 기술 구성

**3대 핵심 기술(VLM + RAG + GUI 자동화)이 통합되어 "화면을 보고 → 판단하고 → 실행"하는 파이프라인 완성**

| 기술 영역 | 세부 내용 |
|-----------|----------|
| **VLM (Vision Language Model)** | Qwen3-VL / Kimi 2를 활용한 화면 상태 인식 및 의사결정. 화면 캡처 이미지와 텍스트 프롬프트를 입력 → JSON 형식의 액션 출력 (클릭 좌표, 입력 텍스트 등) |
| **RAG (Retrieval-Augmented Generation)** | CCTV에서 추출한 전문가 작업 영상을 CLIP(시각) + bge-m3(텍스트) 임베딩으로 인덱싱. 현재 화면과 유사한 과거 장면을 100ms 이내 검색하여 VLM 프롬프트에 보강 → 성공률 15~20%p 향상 |
| **GUI 자동화** | mss(화면 캡처, ~10ms) + pynput(마우스/키보드 제어) 기반 크로스 플랫폼 입력 자동화. 단일 액션 <200ms 실행 |

---

## Slide 6. 시스템 아키텍처

**H200 GPU 클러스터(오프라인 분석) + 자동화 PC(실시간 제어) + 엔지니어 UI의 3-Tier 구조**

```
┌──────────────────────────────────────────────────────┐
│              H200 GPU 클러스터 (오프라인)                │
│  • VLM 추론 서버 (Qwen3-VL API)                       │
│  • CCTV 영상 대량 분석 (프레임 추출 + 임베딩)            │
│  • RAG 인덱스 빌드 (MongoDB + FAISS)                   │
└───────────────────────┬──────────────────────────────┘
                        │ REST API
┌───────────────────────┼──────────────────────────────┐
│          자동화 전용 PC │(실시간)                        │
│  ┌────────────┐  ┌────┴───────┐  ┌────────────────┐  │
│  │ 화면 캡처   │→│ AI Agent   │→│ 마우스/키보드    │  │
│  │ (mss)      │  │ • 상태 매칭 │  │ 제어 (pynput)  │  │
│  └────────────┘  │ • VLM 판단 │  └────────────────┘  │
│                   │ • RAG 검색 │         ↓            │
│                   └────────────┘  ┌────────────────┐  │
│                                    │  RCS (VM)      │  │
│                                    │  장비 원격 제어  │  │
│                                    └────────────────┘  │
└───────────────────────┬──────────────────────────────┘
                        │ WebSocket
┌───────────────────────┼──────────────────────────────┐
│          엔지니어 인터페이스 (Vue)                        │
│  • 화면 미러링  • AI 채팅  • 제어 패널 (모드 전환)       │
└──────────────────────────────────────────────────────┘
```

---

## Slide 7. 자동화 실행 흐름 (How)

**캡처 → 상태 매칭 → RAG 보강 → VLM 판단 → 실행 → 검증의 6단계 루프가 자동 반복**

| 단계 | 처리 내용 | 소요 시간 |
|------|----------|----------|
| ① 화면 캡처 | mss로 VM 창 캡처 → PNG 이미지 | ~10ms |
| ② 빠른 상태 매칭 | CLIP 임베딩 → FAISS 유사도 검색 (50% 히트율) | ~5ms |
| ③ RAG 컨텍스트 검색 | 시각 + 텍스트 하이브리드 검색 → 유사 사례 + 전문가 액션 + 에러 패턴 | ~80ms |
| ④ VLM 의사결정 | RAG 보강 프롬프트 + 화면 이미지 → Qwen3-VL API → JSON 액션 응답 | ~1,500ms |
| ⑤ 액션 실행 | 마우스 이동/클릭 또는 키보드 입력 | <200ms |
| ⑥ 결과 검증 | 재캡처 → 성공/실패 판단 → 실패 시 ③부터 재시도 (최대 10회) | ~1,500ms |

**1 사이클 총 소요: ~3.3초** (RAG 포함 시 +100ms, 정확도 15~20%p 향상)

---

## Slide 8. RAG 시스템 — CCTV 기반 전문가 지식 활용

**엔지니어 CCTV 작업 영상에서 "언제, 어떤 화면에서, 무엇을 했는지"를 추출하여 AI의 판단 근거로 활용**

| 오프라인 전처리 (1회) | 실시간 활용 |
|---------------------|------------|
| CCTV AVI 파일 → 키프레임 추출 (1초 간격) | 현재 화면 캡처 |
| CLIP 시각 임베딩 생성 (512차원) | ↓ |
| EasyOCR 텍스트 추출 (한/영) | CLIP + bge-m3 하이브리드 검색 |
| 전문가 액션 시퀀스 라벨링 (클릭/입력/대기) | ↓ |
| 에러 패턴 감지 (RGB 고속 + VLM 분석) | Top-K 유사 프레임 + 전문가 액션 + 에러 패턴 |
| bge-m3 텍스트 임베딩 생성 (1,024차원) | ↓ |
| MongoDB + FAISS 인덱스 저장 | VLM 프롬프트에 컨텍스트 주입 |
| **CCTV 10시간 기준 ~5시간 처리, 약 2.8GB 저장** | **P95 검색 지연 <100ms** |

---

## Slide 9. 제어 모드 — Supervised Autonomy

**Tesla FSD와 유사한 단계별 자율성 모델 적용: AI가 주도하되 엔지니어가 언제든 개입 가능**

| 모드 | AI 동작 | 엔지니어 동작 | 적용 상황 |
|------|---------|-------------|----------|
| **AUTO** | 전체 자동 실행 | 모니터링만 | 검증 완료된 반복 작업 |
| **SUPERVISED** | 자동 실행 + 알림 | 언제든 개입/중단 가능 | **일반 운영 (기본 모드)** |
| **MANUAL** | 대기 (추천만 제공) | 직접 마우스/키보드 조작 | 트러블슈팅, 신규 패턴 |
| **PAUSED** | 대기 | 재개 여부 결정 | 에러 복구, 확인 필요 시 |

- 모드 전환 지연: **<100ms** (즉각 반응)
- VLM 신뢰도 70% 미만 시 자동으로 SUPERVISED → MANUAL 전환 요청
- 연속 실패 10회 시 자동 중단, 엔지니어에게 알림

---

## Slide 10. 구현 로드맵

**5개 Phase, 약 25주에 걸쳐 PoC → Alpha → UI → 파일럿 → 확장 단계로 진행**

| Phase | 기간 | 주요 내용 | 마일스톤 |
|-------|------|----------|---------|
| **Phase 1: 환경 구축** | 1~4주 | 자동화 PC 세팅, VM 캡처 + 입력 전달 검증, VLM API 연동, 초기 데이터 수집 (스크린샷 100장) | TC-01, TC-04 통과 |
| **Phase 2: 핵심 기능** | 5~10주 | 상태 매칭(CLIP+FAISS), 측정 결과 판단, 워크플로우 엔진, RAG 시스템 구축 | TC-02~TC-08 통과 |
| **Phase 3: UI 개발** | 11~14주 | Vue 프론트엔드 (화면 미러링, 제어 패널), AI-엔지니어 채팅 인터페이스 | TC-09, TC-10 통과 |
| **Phase 4: 통합 & 파일럿** | 15~20주 | 통합 테스트, 실제 장비 1대 파일럿, 엔지니어 피드백 반영, v1.0 릴리즈 | 성공률 70%↑ |
| **Phase 5: 확장** | 21주~ | CCTV 영상 분석 파이프라인, 다중 장비 확장, 성공률 90% 달성 | 다중 장비 배포 |

---

## Slide 11. 성과 목표 (KPI)

**정량적 지표 기반의 단계별 목표 설정 — 최종 목표: 성공률 90%, 시간 단축 50%**

| 지표 | Phase 1~2 | Phase 3~4 | 최종 (Phase 5) |
|------|-----------|-----------|---------------|
| **상태 매칭 정확도** | 80% | 90% | 95% |
| **측정 결과 판단 정확도** | 75% | 85% | 90% |
| **Recipe 셋업 성공률** | - | 50~70% | **>90%** |
| **평균 재시도 횟수** | - | <5회 | **<3회** |
| **사람 개입 비율** | - | <40% | **<20%** |
| **작업 시간 단축률** | - | 30% | **>50%** |

---

## Slide 12. 예상 허들 및 대응 방안

**핵심 리스크를 사전 식별하고 구체적인 대응 전략을 수립하여 프로젝트 지연을 최소화**

| 예상 허들 | 확률 | 영향 | 대응 방안 |
|-----------|------|------|----------|
| **VM 화면 캡처 품질 저하** (해상도, DPI 차이) | 중 | 높음 | 해상도/스케일 자동 보정 로직 구현, 다양한 환경에서 사전 테스트 |
| **VLM 판단 정확도 미달** (복잡한 화면 상태) | 중 | 높음 | RAG로 컨텍스트 보강 (+15~20%p), 규칙 기반 보완, 프롬프트 엔지니어링 지속 개선 |
| **RCS UI 업데이트** (화면 레이아웃 변경) | 낮 | 높음 | 상태 재학습 프로세스 구축 (새 스크린샷 → 임베딩 → 인덱스 갱신) |
| **보안팀 협조 지연** (네트워크, VM 접근 권한) | 중 | 중 | Host-기반 이미지 제어로 VM 내부 설치 불필요 아키텍처 설계 완료 |
| **VLM Fine-tuning 금지 정책** | 확정 | 중 | RAG + 프롬프트 엔지니어링으로 대체 (Fine-tuning 불필요 설계) |
| **GPU 없는 자동화 PC** | 확정 | 낮 | H200 클러스터로 무거운 연산 분리, PC는 API 호출만 수행 |
| **엔지니어 수용성** (새 시스템 저항) | 중 | 중 | Supervised 모드로 시작 (강제 자동화 없음), 초기부터 파일럿 참여, 피드백 반영 |
| **CCTV 영상 확보 지연** | 중 | 중 | Phase 1~2는 CCTV 없이 진행 가능, RAG는 Phase 5에서 본격 활용 |

---

## Slide 13. 기대 효과

**단순 자동화를 넘어, 전문가 지식의 자산화와 확장 가능한 자동화 플랫폼 구축**

| 정량적 효과 | 정성적 효과 |
|------------|------------|
| **작업 시간 50% 이상 단축** — 수동 조작 시간 절감 | **전문가 노하우 자산화** — CCTV 영상 + 작업 이력이 MongoDB에 축적되어 인력 이탈에도 지식 보존 |
| **자동화 성공률 90%** — AI가 대부분의 Recipe 셋업 자동 완료 | **업무 품질 표준화** — 엔지니어 숙련도에 관계없이 일관된 품질 확보 |
| **사람 개입 20% 이하** — 1명이 다수 장비 모니터링 가능 | **확장 가능한 플랫폼** — CD-SEM, VeritySEM 이후 AFM 등 다른 장비로 확장 가능 |
| **재시도 횟수 평균 3회 이하** — 시행착오 감소 | **실시간 협업 체계** — AI 채팅 인터페이스로 엔지니어-AI 간 소통 채널 확보 |
| **CCTV 100시간 분석에 ~2.8GB, P95 검색 <100ms** — 경량 인프라 | **자기 개선 시스템** — 사용할수록 RAG 데이터 축적, 지속적 성능 향상 |

---

## Slide 14. 필요 리소스

**자동화 PC + 테스트 장비 + CCTV 영상 확보가 프로젝트 시작의 핵심 선행 조건**

| 리소스 | 용도 | 현재 상태 | 필요 시점 |
|--------|------|----------|----------|
| **자동화 전용 PC** (Windows) | AI Agent 실행, RCS 접근 | 요청 예정 | Phase 1 시작 전 |
| **H200 GPU 클러스터 접근** | VLM 추론 서버, CCTV 영상 분석 | ✅ 확보됨 | Phase 1 |
| **Qwen3-VL / Kimi 2 API** | 화면 상태 인식, 의사결정 | ✅ 확보됨 (사내 제공) | Phase 1 |
| **MongoDB 서버** | 워크플로우/이력/임베딩 저장 | 구축 필요 | Phase 2 |
| **테스트 장비** (CD-SEM, VeritySEM) | 파일럿 테스트 | 협의 필요 | Phase 4 |
| **CCTV 작업 영상** (20+개) | 전문가 워크플로우 추출 | 협의 필요 | Phase 5 |

---

## Slide 15. 즉시 실행 항목 (Next Steps)

**Phase 1 착수를 위한 6개 즉시 액션 아이템**

| 순서 | 액션 아이템 | 담당 | 기한 |
|------|------------|------|------|
| 1 | 자동화 전용 PC 요청 및 확보 | TBD | 1주차 |
| 2 | RCS 화면 스크린샷 50장 수집 | TBD | 2주차 |
| 3 | VM 창 캡처 + 클릭 전달 PoC 검증 | TBD | 2주차 |
| 4 | Qwen3-VL API 연동 테스트 | TBD | 3주차 |
| 5 | 화면 상태 10종 정의 및 라벨링 | TBD | 4주차 |
| 6 | CCTV 영상 샘플 확보 협의 시작 | TBD | 4주차 |

**의사결정 요청 사항:**
- 자동화 전용 PC 예산 승인
- 파일럿 대상 장비 지정 (CD-SEM 또는 VeritySEM 중 1대)
- CCTV 영상 접근 권한 승인

---

## 부록: 용어 설명

| 용어 | 설명 |
|------|------|
| **CD-SEM** | Critical Dimension Scanning Electron Microscope. e-beam 기반 반도체 CD 측정 장비 |
| **VeritySEM** | e-beam 기반 계측(metrology)용 SEM 장비 |
| **RCS** | Remote Control System. 장비 원격 제어 소프트웨어 |
| **Recipe** | 측정 장비의 동작 설정 및 측정 위치 정보 집합 |
| **VLM** | Vision Language Model. 이미지와 텍스트를 동시에 이해하는 AI 모델 |
| **RAG** | Retrieval-Augmented Generation. 관련 정보를 검색하여 AI 응답 품질을 높이는 기법 |
| **CLIP** | Contrastive Language-Image Pre-training. 이미지를 벡터로 변환하는 OpenAI 모델 |
| **FAISS** | Facebook AI Similarity Search. 대규모 벡터 유사도 검색 라이브러리 |
| **Supervised Autonomy** | AI가 주도하되 사람이 언제든 개입 가능한 제어 방식 |
