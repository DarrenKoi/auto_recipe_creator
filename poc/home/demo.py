"""
Home Study Demo - GUI ìë™í™” í•™ìŠµ

Hugging Face ë¬´ë£Œ APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì§‘ì—ì„œ GUI ìë™í™”ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
GPU ì—†ì´ ë™ì‘í•˜ë©°, íšŒì‚¬ API ì—†ì´ë„ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Usage:
    # í™˜ê²½ ì„¤ì • (ìµœì´ˆ 1íšŒ)
    export HF_TOKEN="hf_xxxx"

    # ê¸°ë³¸ ë°ëª¨ (í™”ë©´ ë¶„ì„)
    uv run python -m poc.home.demo

    # íŠ¹ì • ëª¨ë“œ ì‹¤í–‰
    uv run python -m poc.home.demo --mode screen_analysis
    uv run python -m poc.home.demo --mode object_detection
    uv run python -m poc.home.demo --mode ui_elements
    uv run python -m poc.home.demo --mode interactive
"""

import sys
import os
import time
import json
from io import BytesIO
from dataclasses import dataclass, field
from typing import List, Optional

# Windows ì½˜ì†” ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8', errors='replace')

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from test.vlm_input_control import ScreenCapture, MouseController, KeyboardController
from poc.home.hf_vlm import HuggingFaceVLM, HFModel, VLMResponse


@dataclass
class DemoMetrics:
    """ë°ëª¨ ì„±ëŠ¥ ë©”íŠ¸ë¦­"""
    total_requests: int = 0
    successful: int = 0
    failed: int = 0
    latencies: List[float] = field(default_factory=list)

    def add(self, latency_ms: float, success: bool):
        self.total_requests += 1
        self.latencies.append(latency_ms)
        if success:
            self.successful += 1
        else:
            self.failed += 1

    def print_summary(self):
        print("\n" + "=" * 60)
        print("ğŸ“Š ë°ëª¨ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"ì´ ìš”ì²­ ìˆ˜: {self.total_requests}")
        print(f"ì„±ê³µ: {self.successful}")
        print(f"ì‹¤íŒ¨: {self.failed}")
        if self.latencies:
            avg = sum(self.latencies) / len(self.latencies)
            print(f"í‰ê·  ì‘ë‹µ ì‹œê°„: {avg:.0f}ms")
            print(f"ìµœì†Œ: {min(self.latencies):.0f}ms")
            print(f"ìµœëŒ€: {max(self.latencies):.0f}ms")
        print("=" * 60)


class HomeAutomationDemo:
    """ì§‘ì—ì„œ GUI ìë™í™”ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•œ ë°ëª¨"""

    def __init__(
        self,
        model: HFModel = HFModel.QWEN2_VL_7B,
        safe_mode: bool = True
    ):
        """
        Args:
            model: ì‚¬ìš©í•  HuggingFace ëª¨ë¸
            safe_mode: Trueë©´ ì‹¤ì œ ë§ˆìš°ìŠ¤/í‚¤ë³´ë“œ ì œì–´ ì•ˆ í•¨
        """
        self.safe_mode = safe_mode
        self.metrics = DemoMetrics()

        # ëª¨ë“ˆ ì´ˆê¸°í™”
        self.screen = ScreenCapture()
        self.mouse = MouseController()
        self.keyboard = KeyboardController()

        print(f"\n[INFO] Home Automation Demo ì´ˆê¸°í™”")
        print(f"[INFO] Safe Mode: {safe_mode}")

        # VLM ì´ˆê¸°í™”
        try:
            self.vlm = HuggingFaceVLM(model=model)
        except ImportError as e:
            print(f"\n[ERROR] {e}")
            print("\n[í•´ê²° ë°©ë²•]")
            print("  1. uv sync --extra home")
            print("  2. export HF_TOKEN='your_token'")
            sys.exit(1)

    def _capture_screen(self) -> bytes:
        """í™”ë©´ ìº¡ì²˜ í›„ PNG ë°”ì´íŠ¸ë¡œ ë°˜í™˜"""
        # ScreenCapture.capture_full_screen()ì€ ì´ë¯¸ PNG ë°”ì´íŠ¸ë¥¼ ë°˜í™˜
        screenshot_bytes = self.screen.capture_full_screen(save=False)
        return screenshot_bytes

    def demo_screen_analysis(self):
        """
        ë°ëª¨ 1: í™”ë©´ ë¶„ì„

        í˜„ì¬ í™”ë©´ì„ ìº¡ì²˜í•˜ê³  VLMìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.
        """
        print("\n" + "=" * 60)
        print("ğŸ” ë°ëª¨ 1: í™”ë©´ ë¶„ì„")
        print("=" * 60)

        print("\n[1/3] í™”ë©´ ìº¡ì²˜ ì¤‘...")
        start = time.time()
        image = self._capture_screen()
        capture_time = (time.time() - start) * 1000
        print(f"[INFO] ìº¡ì²˜ ì™„ë£Œ ({capture_time:.0f}ms, {len(image)/1024:.1f}KB)")

        print("\n[2/3] VLM ë¶„ì„ ì¤‘... (ì²« ìš”ì²­ì€ ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ ëŠë¦´ ìˆ˜ ìˆìŒ)")
        response = self.vlm.analyze_screen(
            image,
            "ì´ í™”ë©´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ì–´ë–¤ ì• í”Œë¦¬ì¼€ì´ì…˜ì´ê³ , ë¬´ì—‡ì„ í•˜ê³  ìˆëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”."
        )

        print(f"\n[3/3] ë¶„ì„ ê²°ê³¼ ({response.latency_ms:.0f}ms):")
        print("-" * 60)
        if response.success:
            print(response.content)
        else:
            print(f"[ERROR] {response.error}")
        print("-" * 60)

        self.metrics.add(response.latency_ms, response.success)

    def demo_ui_elements(self):
        """
        ë°ëª¨ 2: UI ìš”ì†Œ ë¶„ì„

        í™”ë©´ì—ì„œ í´ë¦­ ê°€ëŠ¥í•œ UI ìš”ì†Œë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        """
        print("\n" + "=" * 60)
        print("ğŸ¯ ë°ëª¨ 2: UI ìš”ì†Œ ë¶„ì„")
        print("=" * 60)

        print("\n[1/3] í™”ë©´ ìº¡ì²˜ ì¤‘...")
        image = self._capture_screen()

        print("\n[2/3] UI ìš”ì†Œ ë¶„ì„ ì¤‘...")
        response = self.vlm.analyze_ui_elements(image, return_json=True)

        print(f"\n[3/3] ë¶„ì„ ê²°ê³¼ ({response.latency_ms:.0f}ms):")
        print("-" * 60)

        if response.success:
            try:
                # JSON íŒŒì‹± ì‹œë„
                content = response.content
                # JSON ë¸”ë¡ ì¶”ì¶œ
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    content = content[start:end].strip()
                elif "```" in content:
                    start = content.find("```") + 3
                    end = content.find("```", start)
                    content = content[start:end].strip()

                data = json.loads(content)
                print(f"í™”ë©´ ìœ í˜•: {data.get('screen_type', 'N/A')}")

                elements = data.get('ui_elements', [])
                print(f"\nUI ìš”ì†Œ ({len(elements)}ê°œ):")
                for i, elem in enumerate(elements[:10], 1):  # ìµœëŒ€ 10ê°œ
                    print(f"  {i}. [{elem.get('type', '?')}] {elem.get('name', 'N/A')}")
                    if elem.get('text'):
                        print(f"      í…ìŠ¤íŠ¸: {elem.get('text')}")

                actions = data.get('possible_actions', [])
                if actions:
                    print(f"\nê°€ëŠ¥í•œ ì•¡ì…˜:")
                    for action in actions[:5]:
                        print(f"  - {action}")

            except json.JSONDecodeError:
                print("[WARN] JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì¶œë ¥:")
                print(response.content[:500])
        else:
            print(f"[ERROR] {response.error}")

        print("-" * 60)
        self.metrics.add(response.latency_ms, response.success)

    def demo_object_detection(self):
        """
        ë°ëª¨ 3: ê°ì²´ íƒì§€

        DETR ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ ê°ì²´ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
        (ì°¸ê³ : ì¼ë°˜ ê°ì²´ìš©, UI ìš”ì†Œ íƒì§€ì—ëŠ” ì œí•œì )
        """
        print("\n" + "=" * 60)
        print("ğŸ“¦ ë°ëª¨ 3: ê°ì²´ íƒì§€ (DETR)")
        print("=" * 60)

        print("\n[1/2] í™”ë©´ ìº¡ì²˜ ì¤‘...")
        image = self._capture_screen()

        print("\n[2/2] ê°ì²´ íƒì§€ ì¤‘...")
        start = time.time()
        objects = self.vlm.detect_objects(image)
        latency = (time.time() - start) * 1000

        print(f"\níƒì§€ ê²°ê³¼ ({latency:.0f}ms):")
        print("-" * 60)
        if objects:
            for i, obj in enumerate(objects[:15], 1):
                print(f"  {i}. {obj.label} (ì‹ ë¢°ë„: {obj.score:.2%})")
                print(f"      ìœ„ì¹˜: {obj.bbox}")
        else:
            print("  íƒì§€ëœ ê°ì²´ ì—†ìŒ (UI ìš”ì†Œ íƒì§€ì—ëŠ” VLM ë¶„ì„ì´ ë” íš¨ê³¼ì )")
        print("-" * 60)

        self.metrics.add(latency, len(objects) > 0)

    def demo_interactive(self):
        """
        ë°ëª¨ 4: ëŒ€í™”í˜• í™”ë©´ ë¶„ì„

        ì‚¬ìš©ìê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ í˜„ì¬ í™”ë©´ì— ëŒ€í•´ ë‹µë³€í•©ë‹ˆë‹¤.
        """
        print("\n" + "=" * 60)
        print("ğŸ’¬ ë°ëª¨ 4: ëŒ€í™”í˜• í™”ë©´ ë¶„ì„")
        print("=" * 60)
        print("\ní˜„ì¬ í™”ë©´ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")
        print("'q' ë˜ëŠ” 'quit'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œí•©ë‹ˆë‹¤.\n")

        while True:
            try:
                question = input("ì§ˆë¬¸: ").strip()
            except (EOFError, KeyboardInterrupt):
                print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            if question.lower() in ['q', 'quit', 'exit']:
                print("ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break

            if not question:
                continue

            print("\n[INFO] í™”ë©´ ìº¡ì²˜ ë° ë¶„ì„ ì¤‘...")
            image = self._capture_screen()
            response = self.vlm.analyze_screen(image, question)

            print(f"\në‹µë³€ ({response.latency_ms:.0f}ms):")
            print("-" * 40)
            if response.success:
                print(response.content)
            else:
                print(f"[ERROR] {response.error}")
            print("-" * 40 + "\n")

            self.metrics.add(response.latency_ms, response.success)

    def run_all_demos(self):
        """ëª¨ë“  ë°ëª¨ ìˆœì°¨ ì‹¤í–‰"""
        print("\n" + "=" * 60)
        print("ğŸ  Home Study Demo - GUI ìë™í™” í•™ìŠµ")
        print("=" * 60)
        print("\nHugging Face ë¬´ë£Œ APIë¥¼ ì‚¬ìš©í•˜ì—¬ í™”ë©´ ë¶„ì„ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        print("ì²« ë²ˆì§¸ ìš”ì²­ì€ ëª¨ë¸ ë¡œë”©ìœ¼ë¡œ ì¸í•´ ëŠë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n")

        input("ì¤€ë¹„ë˜ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”...")

        # ë°ëª¨ ì‹¤í–‰
        self.demo_screen_analysis()
        self.demo_ui_elements()

        # ìµœì¢… ìš”ì•½
        self.metrics.print_summary()


def main():
    import argparse

    parser = argparse.ArgumentParser(description="Home GUI Automation Demo")
    parser.add_argument(
        "--mode",
        choices=["all", "screen_analysis", "ui_elements", "object_detection", "interactive"],
        default="all",
        help="ì‹¤í–‰í•  ë°ëª¨ ëª¨ë“œ"
    )
    parser.add_argument(
        "--model",
        choices=["qwen2_vl_7b", "qwen2_vl_2b", "llava"],
        default="qwen2_vl_7b",
        help="ì‚¬ìš©í•  VLM ëª¨ë¸"
    )
    parser.add_argument(
        "--live",
        action="store_true",
        help="Live mode (ì‹¤ì œ ë§ˆìš°ìŠ¤/í‚¤ë³´ë“œ ì œì–´)"
    )

    args = parser.parse_args()

    # ëª¨ë¸ ë§¤í•‘
    model_map = {
        "qwen2_vl_7b": HFModel.QWEN2_VL_7B,
        "qwen2_vl_2b": HFModel.QWEN2_VL_2B,
        "llava": HFModel.LLAVA_1_5_7B,
    }

    demo = HomeAutomationDemo(
        model=model_map[args.model],
        safe_mode=not args.live
    )

    # ëª¨ë“œë³„ ì‹¤í–‰
    if args.mode == "all":
        demo.run_all_demos()
    elif args.mode == "screen_analysis":
        demo.demo_screen_analysis()
        demo.metrics.print_summary()
    elif args.mode == "ui_elements":
        demo.demo_ui_elements()
        demo.metrics.print_summary()
    elif args.mode == "object_detection":
        demo.demo_object_detection()
        demo.metrics.print_summary()
    elif args.mode == "interactive":
        demo.demo_interactive()
        demo.metrics.print_summary()


if __name__ == "__main__":
    main()
